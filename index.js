require('dotenv').config();
const nacl = require('tweetnacl');

const { Client, GatewayIntentBits, Events } = require("discord.js");
const { 
    joinVoiceChannel, 
    createAudioPlayer, 
    createAudioResource, 
    AudioPlayerStatus, 
    VoiceConnectionStatus, 
    entersState,
    StreamType 
} = require("@discordjs/voice");
const sdk = require("microsoft-cognitiveservices-speech-sdk");
const { PassThrough } = require("stream");
const http = require("http");

const port = process.env.PORT || 8000;
http.createServer((req, res) => { res.writeHead(200); res.end("Alive"); }).listen(port);

const client = new Client({
  intents: [
    GatewayIntentBits.Guilds, 
    GatewayIntentBits.GuildVoiceStates, 
    GatewayIntentBits.GuildMembers, 
    GatewayIntentBits.MessageContent
  ]
});

client.once(Events.ClientReady, () => {
    console.log(`âœ… Î— Î‘Î¸Î·Î½Î¬ ÎµÎ¯Î½Î±Î¹ Online!`);
});

async function playSpeech(text, voiceChannel) {
  const connection = joinVoiceChannel({
    channelId: voiceChannel.id,
    guildId: voiceChannel.guild.id,
    adapterCreator: voiceChannel.guild.voiceAdapterCreator,
    selfDeaf: false,
  });

  try {
    await entersState(connection, VoiceConnectionStatus.Ready, 20000);
    
    const speechConfig = sdk.SpeechConfig.fromSubscription(process.env.AZURE_SPEECH_KEY, "westeurope");
    const synthesizer = new sdk.SpeechSynthesizer(speechConfig);
    const ssml = `<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="el-GR"><voice name="el-GR-AthinaNeural"><prosody rate="0.85">${text}</prosody></voice></speak>`;

    synthesizer.speakSsmlAsync(ssml, result => {
      if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
        // Î§ÏÎ®ÏƒÎ· PassThrough Î³Î¹Î± Ï€Î¹Î¿ ÏƒÏ„Î±Î¸ÎµÏÏŒ streaming Î®Ï‡Î¿Ï…
        const bufferStream = new PassThrough();
        bufferStream.end(Buffer.from(result.audioData));

        const resource = createAudioResource(bufferStream, {
          inputType: StreamType.Arbitrary,
          inlineVolume: true
        });

        const player = createAudioPlayer();
        connection.subscribe(player);
        player.play(resource);

        player.on(AudioPlayerStatus.Playing, () => {
            console.log("ğŸ”Š ÎÎµÎºÎ¯Î½Î·ÏƒÎµ Î· Î¿Î¼Î¹Î»Î¯Î±!");
        });

        player.on(AudioPlayerStatus.Idle, () => {
          // Î”Î¯Î½Î¿Ï…Î¼Îµ 2 Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î± Ï€ÏÎ¹Î½ Ï„Î·Î½ Î±Ï€Î¿ÏƒÏÎ½Î´ÎµÏƒÎ· Î³Î¹Î± Î½Î± Î¼Î·Î½ ÎºÏŒÎ²ÎµÏ„Î±Î¹ Î· Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± Î»Î­Î¾Î·
          setTimeout(() => {
            if (connection.state.status !== VoiceConnectionStatus.Destroyed) {
                connection.destroy();
                console.log("ğŸ”Œ Î‘Ï€Î¿ÏƒÏ…Î½Î´Î­Î¸Î·ÎºÎµ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¬.");
            }
          }, 2000);
          synthesizer.close();
        });

        player.on('error', error => {
          console.error(`Audio Player Error: ${error.message}`);
          connection.destroy();
        });
      }
    });

  } catch (error) {
    console.error("Î£Ï†Î¬Î»Î¼Î±:", error.message);
    if (connection.state.status !== VoiceConnectionStatus.Destroyed) connection.destroy();
  }
}

client.on("voiceStateUpdate", (oldState, newState) => {
  if (!oldState.channelId && newState.channelId && !newState.member.user.bot) {
    console.log(`ğŸ‘¤ Î•Î¯ÏƒÎ¿Î´Î¿Ï‚ Ï‡ÏÎ®ÏƒÏ„Î·: ${newState.member.displayName}`);
    playSpeech(`ÎšÎ±Î»Ï‰ÏƒÎ®ÏÎ¸ÎµÏ‚ ${newState.member.displayName}`, newState.channel);
  }
});

client.login(process.env.DISCORD_TOKEN);
