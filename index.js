require('dotenv').config();
const http = require("http");

// --- 1. Î‘ÎœÎ•Î£ÎŸÎ£ SERVER Î“Î™Î‘ Î¤ÎŸ RAILWAY ---
const PORT = process.env.PORT || 8080;
http.createServer((req, res) => {
    res.writeHead(200);
    res.end("Health Check OK");
}).listen(PORT, "0.0.0.0", () => {
    console.log(`ğŸŒ Health Check Server on port ${PORT}`);
});

// --- 2. Î¦ÎŸÎ¡Î¤Î©Î£Î— ÎšÎ¡Î¥Î Î¤ÎŸÎ“Î¡Î‘Î¦Î—Î£Î—Î£ ---
// Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿ libsodium-wrappers Ï€Î¿Ï… Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ aead_aes256_gcm
const sodium = require('libsodium-wrappers');
const { Client, GatewayIntentBits, Events } = require("discord.js");
const { 
    joinVoiceChannel, 
    createAudioPlayer, 
    createAudioResource, 
    entersState, 
    VoiceConnectionStatus, 
    StreamType,
    generateDependencyReport
} = require("@discordjs/voice");
const sdk = require("microsoft-cognitiveservices-speech-sdk");
const { PassThrough } = require("stream");

const client = new Client({
  intents: [
    GatewayIntentBits.Guilds, 
    GatewayIntentBits.GuildVoiceStates, 
    GatewayIntentBits.GuildMembers
  ]
});

client.once(Events.ClientReady, async (c) => {
    await sodium.ready; // Î ÎµÏÎ¹Î¼Î­Î½Î¿Ï…Î¼Îµ Î¿Ï€Ï‰ÏƒÎ´Î®Ï€Î¿Ï„Îµ Ï„Î¿ sodium
    console.log(`âœ… Î— Î‘Î¸Î·Î½Î¬ Î¾ÎµÎºÎ¯Î½Î·ÏƒÎµ: ${c.user.tag}`);
    console.log("--- Dependency Report ---");
    console.log(generateDependencyReport());
});

async function playSpeech(text, voiceChannel) {
  // Î•Î¾Î±ÏƒÏ†Î±Î»Î¯Î¶Î¿Ï…Î¼Îµ ÏŒÏ„Î¹ Ï„Î¿ sodium ÎµÎ¯Î½Î±Î¹ Î­Ï„Î¿Î¹Î¼Î¿ Ï€ÏÎ¹Î½ Ï„Î· ÏƒÏÎ½Î´ÎµÏƒÎ·
  await sodium.ready;

  const connection = joinVoiceChannel({
    channelId: voiceChannel.id,
    guildId: voiceChannel.guild.id,
    adapterCreator: voiceChannel.guild.voiceAdapterCreator,
    selfDeaf: false,
  });

  try {
    await entersState(connection, VoiceConnectionStatus.Ready, 20000);
    console.log(`ğŸ”Š Î£ÏÎ½Î´ÎµÏƒÎ· ÎµÏ€Î¹Ï„Ï…Ï‡Î®Ï‚!`);

    const speechConfig = sdk.SpeechConfig.fromSubscription(process.env.AZURE_SPEECH_KEY, "westeurope");
    const synthesizer = new sdk.SpeechSynthesizer(speechConfig);
    
    const ssml = `<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="el-GR">
        <voice name="el-GR-AthinaNeural">
          <prosody rate="0.9">${text}</prosody>
        </voice>
      </speak>`;

    synthesizer.speakSsmlAsync(ssml, result => {
      if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
        const bufferStream = new PassThrough();
        bufferStream.end(Buffer.from(result.audioData));

        const player = createAudioPlayer();
        const resource = createAudioResource(bufferStream, { inputType: StreamType.Arbitrary });
        
        connection.subscribe(player);
        player.play(resource);

        player.on('idle', () => {
          setTimeout(() => {
            if (connection.state.status !== VoiceConnectionStatus.Destroyed) connection.destroy();
          }, 2000);
          synthesizer.close();
        });
      }
    });

  } catch (error) {
    console.error("âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚:", error.message);
    if (connection.state.status !== VoiceConnectionStatus.Destroyed) connection.destroy();
  }
}

client.on("voiceStateUpdate", (oldState, newState) => {
  if (!oldState.channelId && newState.channelId && !newState.member.user.bot) {
    playSpeech(`ÎšÎ±Î»Ï‰ÏƒÎ®ÏÎ¸ÎµÏ‚ ${newState.member.displayName}`, newState.channel);
  }
});

client.login(process.env.DISCORD_TOKEN);
